{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eab32a4-5b20-4884-81a8-f0bea419b679",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b433758-630a-4df1-ab9d-151455b3a57f",
   "metadata": {},
   "source": [
    "Performing sentimal analysis on IMDB dataset using RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38580d05-e78d-40d1-868e-20dc9b1cca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d772b90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.vocab import vocab\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf29c1-52f7-40aa-8d6a-a5dbb7f069e5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3318edb-0f3c-47bb-b0e4-0aba8dfa200b",
   "metadata": {},
   "source": [
    "## Step 1: Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94500a57-be84-4b6d-bc17-62c5e677f5ee",
   "metadata": {},
   "source": [
    "We will use 20,000 examples for training and 5000 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2ff203-3e49-4b4b-8b33-d1af925e4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMDB(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36fb689-6f58-4669-8b6c-cdf2387be032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 5000\n",
      "(2, \"almost every review of this movie I'd seen was pretty bad. It's not pretty bad, it's actually pretty good, though not great. The Judy Garland character could have gotten annoying, but she didn't allow it to. Somewhere along the line, i've become a fan of brooding, overbearing, overacting Van Heflin, at least in the early 40's. Judy's singing is great, but the film missed a great chance by not showing more of their relationship. I gave it a 7.\")\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = random_split(list(train_dataset), [0.8, 0.2])\n",
    "print(len(train_dataset), len(valid_dataset))\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, [1,2,3,4,5])\n",
    "print(train_dataset[1])  # print one example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633515a2-c94e-40a6-8992-038b7fc45f87",
   "metadata": {},
   "source": [
    "## Step 2: Find unique tokens\n",
    "\n",
    "Text processing and finding unique tokens to build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6dc1760-70a8-4522-b2d6-73198724ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "emoji_pattern = re.compile(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\")\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"\n",
    "    Our custom tokenizer function:\n",
    "        1. Remove html markups\n",
    "        2. Preserve emoticons (remove hyphens)\n",
    "        3. Remove punctuation and non-letter characters\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove html markups\n",
    "    # text = re.sub(\"<[^>]*>\", \"\", text)\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text().lower()\n",
    "\n",
    "    # Collect emoticons\n",
    "    emoticons = re.findall(emoji_pattern, text.lower())\n",
    "\n",
    "    # Remove non-letter characters and add emoticons\n",
    "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
    "\n",
    "    # Process the text with spaCy -> takes time!\n",
    "    # doc = nlp(text)\n",
    "    # tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bc52fc-94c0-4783-b36b-6e4ff7e63a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3j/2s54wx4j0qsdwyxcpjx2h2780000gn/T/ipykernel_92484/2716839546.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 69019\n"
     ]
    }
   ],
   "source": [
    "token_counts = Counter()\n",
    "for label, line in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print(f\"Vocab size: {len(token_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502ec94-404e-4538-b079-80f87658b18e",
   "metadata": {},
   "source": [
    "## Step3: Encoding unique token to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747b7c0-aafa-44d6-b730-9ad1a602f13f",
   "metadata": {},
   "source": [
    "Next, we will map each unique word to a unique integer. This can be done manually using a Python dictionary. \n",
    "However, the `torchtext` package already provides a class `vocab` for this. We will also add *padding* and *unknown* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2ec0c3-7cf6-4501-9bd4-dffde1b195a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 457]\n"
     ]
    }
   ],
   "source": [
    "sorted_by_freq_tuples = sorted(\n",
    "    token_counts.items(), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab = vocab(ordered_dict)\n",
    "\n",
    "# Prepend two special tokens \"padding\" and \"unknown\"\n",
    "vocab.insert_token(\"<pad>\", 0) # 0 is placeholder for padding\n",
    "vocab.insert_token(\"<unk>\", 1) # unknown words will be assigned 1\n",
    "vocab.set_default_index(1)\n",
    "print([vocab[token] for token in [\"this\", \"is\", \"an\", \"example\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1f71c2-f348-4d46-8b14-2fc090a12b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Step 3A: Define the transformation functions\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: 1. if x == 2 else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbb518a-85a6-4c9f-a6f2-4eb1d3b79982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Step 3B: wrap the encode and transformation function\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return padded_text_list, label_list, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8d0426-51d1-4f60-88d9-50293b0e88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b6846-d196-4563-b1b5-adb07e9ac7a2",
   "metadata": {},
   "source": [
    "So far, we have converted sequence of words into sequence of integers, and labels of `pos` and `neg` into 1 or 0. However, there is one issue that we need to resolve i.e. the sequences currently have different lengths. Although, in general, RNNs can handle sequences of variable lengths, we still need to make that all the sequences in a mini-batch have the same length to store them efficiently in a tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac20ad-9e3e-4d4f-b9d7-e7e9e73a7c45",
   "metadata": {},
   "source": [
    "PyTorch provides an efficient method `pad_sequence` for this, which we already included in our `collate_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deaaf6a9-fcb1-4374-90aa-d2eeca9c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first batch\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201253da-a1f5-4536-99fb-a2145034001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cbfcbcf-a35a-4679-a977-c176cff33f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75466fcc-45d0-4e94-ab2b-ce60ccccbe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([165,  86, 218, 145])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d10258bd-f776-4720-b541-1cf20bb1df50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 218])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23faa51-1984-4244-9010-6794fa3e227a",
   "metadata": {},
   "source": [
    "As we can see, all the examples are padded to match the maximum size in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc4b0c6c-d232-4330-8c2b-b8473aa60b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec38021-2d8b-4fad-9ca3-7d54cd70bbc5",
   "metadata": {},
   "source": [
    "Now we will convert these integers to input features using `nn.Embedding` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "751843f2-e9d1-4623-a37d-a890acbc132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of using nn.Embedding\n",
    "\n",
    "# embedding = nn.Embedding(num_embeddings=10, embedding_dim=3 ,padding_idx=0)\n",
    "# sample_examples = torch.LongTensor([[1,2,3,4], [5,6,7,0]])\n",
    "\n",
    "# print(embedding(sample_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0584f2f-c91a-43c3-bade-8e8317c9e195",
   "metadata": {},
   "source": [
    "# Step 4: Building our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83fd7e2-b93c-4d7f-bfc2-23fe5908db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test model\n",
    "\n",
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers):\n",
    "#         super().__init__()\n",
    "#         # Add RNN layer\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         # self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         # self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "#         # Add final prediciton head\n",
    "#         self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         _, hidden = self.rnn(x)\n",
    "#         out = hidden[-1, :, :] # we use the final hidden state from the last hidden layer (num_layers, batch_size, hidden_size)\n",
    "#         out = self.fc(out)\n",
    "#         return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4efa5ea2-a569-4e78-a28e-ca96613a7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RNN(64, 32, 2)\n",
    "# model(torch.randn(5,3,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549b116-3dc1-4e57-b0e2-4ffb6ec020b2",
   "metadata": {},
   "source": [
    "Since we have very long sequences, we are going to use an LSTM layer to account for long range effects. \n",
    "\n",
    "We will also use `pack_padded_sequence`  function to prepare the input sequences for efficient processing by RNNs or other sequence processing modules. It eliminates the padding.\n",
    "\n",
    "If you need to obtain the original output sequences, you can \"unpack\" the sequences using the `pad_packed_sequence` function, which will restore the padding and return sequences with the original lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ac10acd-a7de-4cf7-8796-89751bea86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c1f2c7-bf21-4124-bf11-c17890b09d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(69021, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers=1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "100790e1-c6a0-4294-af55-6a42507a7fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60d90a39-cb65-4d29-9b77-90a97c29efd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(69021, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd173b-a6f9-4ece-b551-bc864a343821",
   "metadata": {},
   "source": [
    "# Step 5: Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e1c45f-063e-4d74-9075-653994cacbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        text_batch, label_batch = text_batch.to(device), label_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bccd7f01-2779-41bd-9a6f-a8131656dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            text_batch, label_batch = text_batch.to(device), label_batch.to(device)\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "        return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73e55b72-4a45-4523-a391-e516f9d3011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa5abaef-8450-45d6-a676-2b42c83e6349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3j/2s54wx4j0qsdwyxcpjx2h2780000gn/T/ipykernel_92484/2716839546.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.5958 val_accuracy: 0.6832\n",
      "Epoch 2 accuracy: 0.7284 val_accuracy: 0.7726\n",
      "Epoch 3 accuracy: 0.7416 val_accuracy: 0.6258\n",
      "Epoch 4 accuracy: 0.7480 val_accuracy: 0.7870\n",
      "Epoch 5 accuracy: 0.8602 val_accuracy: 0.8458\n",
      "Epoch 6 accuracy: 0.8986 val_accuracy: 0.8564\n",
      "Epoch 7 accuracy: 0.9231 val_accuracy: 0.8456\n",
      "Epoch 8 accuracy: 0.9419 val_accuracy: 0.8598\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 6\u001b[0m     acc_train, loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     acc_valid, loss_valid \u001b[38;5;241m=\u001b[39m evaluate(valid_dl)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_valid\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      7\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(text_batch, lengths)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, label_batch)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m total_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((pred \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m==\u001b[39m label_batch)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/sr-ml-course/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sr-ml-course/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f\"Epoch {epoch+1} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ca695-83a3-49a0-be52-4b73b2248d85",
   "metadata": {},
   "source": [
    "# Step 6: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e4f781-01e7-457f-a1c5-e0e06bf90b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = IMDB(split=\"test\")\n",
    "test_dataset = list(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a6951-4295-4e8a-aead-e30db7e9fa9f",
   "metadata": {},
   "source": [
    "I got some issue `TypeError: _IterDataPipeSerializationWrapper instance doesn't have valid length`. Converting it into a list solved the `length` issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0de2748c-2e6f-4995-9fef-82470f8caa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da73acfd-24ef-48f9-b893-ad8e78de189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3j/2s54wx4j0qsdwyxcpjx2h2780000gn/T/ipykernel_92484/2716839546.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.85512\n"
     ]
    }
   ],
   "source": [
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f\"Test accuracy: {acc_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d29f0-854d-49d2-bff1-d8e839de2c49",
   "metadata": {},
   "source": [
    "# Testing Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbd21709-2e8e-499a-a700-afa91e90512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = torch.cat((hidden[-2, :, :],\n",
    "                        hidden[-1, :, :]), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f5aee73-be41-40f1-abb2-c02fd2745121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (embedding): Embedding(69021, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiRNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b161a06-3efd-49f3-b98c-22ce8145eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f\"Epoch {epoch+1} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8e76d-bf60-4c2b-81bc-04cb7a7a150a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3a717-211a-41f4-ab7a-9e315534ba36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
